
#'Use H2O’s Deep Learning to perform regression or classification on a dataset,
#'extact non-linear features generated by the deep neural network,
#'and/or detect anomalies using a deep learning model with auto-encoding.

# In this example, we will use the prostate dataset available within the h2o package:
library(h2o)
library(sparklyr)


# Mac
# Sys.setenv(SPARK_HOME = "/Users/rohitpittu/spark/spark-2.1.0-bin-hadoop2.7")
Sys.setenv(SPARK_HOME = paste0(spark_install_dir(),"/spark-2.0.0-bin-hadoop2.7"))
Sys.getenv("SPARK_HOME")

# spark connection
sc <- spark_connect(master = 'local',version="2.1.0")


path <- system.file("extdata", "prostate.csv", package = "h2o")
prostate_df <- spark_read_csv(sc, "prostate", path)
head(prostate_df)

#' Once we’ve done whatever data manipulation is required to run our model
#' we’ll get a reference to it as an h2o frame then
#' split it into training and test sets using the h2o.splitFrame function:

# prostate_hf <- as_h2o_frame(sc, prostate_df,strict_version_check = F)
h2o.init()
prostate_hf<-as.h2o(prostate_df)
splits <- h2o.splitFrame(prostate_hf, seed = 1)


# Next we define the response and predictor columns.

y <- "VOL"

# Remove response and ID cols
x <- setdiff(names(prostate_hf), c("ID", y))

# Fit the deep neural net model

dl_fit <- h2o.deeplearning(x = x, y = y,
                           training_frame = splits[[1]],
                           epochs = 15,
                           activation = "Maxout",
                           hidden = c(10, 5, 10),
                           input_dropout_ratio = 0.7)


# Evaluate performance on a test set:

  h2o.performance(dl_fit, newdata = splits[[2]])


dl_fit
